{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API PARA RECOMENDACIÓN DE VIDEOJUEGOS EN STEAM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL (Extraction, Transformation, Load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar la cargar normal de los archivos se presentaban errores porque estaban en formato gzip, es por eso que antes de generar codigo éstos se extrajeron en la misma carpeta para evitar futuras complicaciones y optimizar el código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, dos archivos archivos tienen sólo comilla simple (') en lugar de comillas dobles (\"), es decir, los archivos estan corruptos y adicionalmente anidados. Esto también genera un error al crear el dataframe así que se prefiere extraer y limpiar los archivos uno por uno para evitar problemas futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- steam_games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el archivo steam_games no había ningún problema así que este es el primero que se carga:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON en un DataFrame\n",
    "steam_games = pd.read_json('output_steam_games.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- user_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para cargar (o más bien crear) el archivo user_reviews es necesario hacer algunas modificaciones, y es por eso que se prefiere guardar línea por línea para poder aplicar dichos cambios. ACLARACIÓN: Se prefiere realizar el proceso de limpieza de forma manual debido a que los recursos que se tienen para manipular los datos son muy escasos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "jlines = []\n",
    "# Abrir el archivo JSON en modo lectura\n",
    "with open('australian_user_reviews.json', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Guardar las líneas del archivo JSON\n",
    "for line in lines:\n",
    "    jlines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el proceso de ETL se pudo evidenciar tres casos puntuales donde en \"reviews\" se encontró respuestas que afectaban el procedimiento de limpieza de datos de forma negativa (se comentará más adelante el por qué), y es por esto que se decide hacer una modificación manual de \"{\" por \"(\" y de \"}\" por \")\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(jlines)):\n",
    "    jlines[i] = jlines[i].replace('{LINK REMOVED}',\"(LINK REMOVED)\")\n",
    "    jlines[i] = jlines[i].replace('{誰是殺手}',\"(誰是殺手)\")\n",
    "    jlines[i] = jlines[i].replace(\"}{@r|)c0r3\",\")(@r|)c0r3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tener un archivo json limpio se decide hacer un diccionario con las mismas columnas originales y luego con este crear un nuevo archivo, dado que es más efectivo y seguro que reemplazar el archivo de user_reviews. Para esto hay que extraer la información de las columnas en el archivo json original; las principales columnas son user_id, user_url y reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer la información de las tres columnas principales del archivo json original\n",
    "user_id = []\n",
    "user_url = []\n",
    "reviews = []\n",
    "\n",
    "for line in jlines:\n",
    "    match = re.search(r\"'user_id':\\s+'([^']+)'[^}]*'user_url':\\s+'([^']+)'[^}]*'reviews':\\s+(\\[.*\\])\", line)\n",
    "    if match:\n",
    "        user_id.append(match.group(1))\n",
    "        user_url.append(match.group(2))\n",
    "        reviews.append(match.group(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidamente notamos que la columna reviews a su vez tiene columnas con información útil, así que extraemos los datos de la columna reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Como se puede ver en el código, el requerimiento para extraer la información de reviews es que los caracteres estén entre \"{\" y \"}\", es por esto que comentarios como \"{LINK REMOVED}\" afectaba negativamente a nuestro proceso de organización. Por lo tanto, al ser sólo tres casos puntuales se decide cambiar los \"{ }\" por \"()\" respectivamente rn fichas reseñas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data_reviews = []\n",
    "\n",
    "for review in reviews:\n",
    "    # Encuentra los datos entre '[' y ']' en cada revisión -> Para extraer todos los caracteres de reviews\n",
    "    matches = re.findall(r'\\{(.*?)\\}', review)\n",
    "    for match in matches:\n",
    "        extracted_data_reviews.append('{'+match+'}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez con los datos individuales de cada columna limpios y listos procedemos a extraer la información de todas las columnas de reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Como algunos comentarios de review presentan comillas es necesario hacer una extraccion aparte para esta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "funny = []\n",
    "posted = []\n",
    "last_edited = []\n",
    "item_id = []\n",
    "helpful = []\n",
    "recommend = []\n",
    "\n",
    "for line in extracted_data_reviews:\n",
    "    match_funny = re.search(r\"'funny':\\s+'([^']+)'[^}]\", line)\n",
    "    match_posted = re.search(r\"'posted':\\s+'([^']+)'\", line)\n",
    "    match_last_edited = re.search(r\"'last_edited':\\s+'([^']+)'\", line)\n",
    "    match_item_id = re.search(r\"'item_id':\\s+'([^']+)'[^}]\", line)\n",
    "    match_helpful = re.search(r\"'helpful':\\s+'([^']+)'[^}]\", line)\n",
    "    match_recommend = re.search(r\"'recommend':\\s+([a-zA-Z]+)\", line)\n",
    "    if match_funny:\n",
    "        funny.append(match_funny.group(1))\n",
    "    if not match_funny:\n",
    "        funny.append(\"\")\n",
    "    if match_posted:\n",
    "        posted.append(match_posted.group(1))\n",
    "    if match_last_edited:\n",
    "        last_edited.append(match_last_edited.group(1))\n",
    "    if not match_last_edited:\n",
    "        last_edited.append(\"\")\n",
    "    if match_item_id:\n",
    "        item_id.append(match_item_id.group(1))\n",
    "    if match_helpful:\n",
    "        helpful.append(match_helpful.group(1))\n",
    "    if match_recommend:\n",
    "        recommend.append(match_recommend.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = []\n",
    "for i in range(len(extracted_data_reviews)):\n",
    "    data = extracted_data_reviews[i]\n",
    "\n",
    "    # Encontrar la posición del inicio de la reseña\n",
    "    review_start = data.find(\"'review': \") + len(\"'review': \")\n",
    "\n",
    "    # Encontrar la posición del final de la reseña\n",
    "    review_end = data.find(\"}\", review_start)\n",
    "\n",
    "    # Extraer el texto de la reseña\n",
    "    review_text = data[review_start:review_end]\n",
    "\n",
    "    # Reemplazar comillas dobles escapadas con comillas dobles normales\n",
    "    review_text = review_text.replace('\\'\\'', '\\'').replace('\"',\"'\")\n",
    "    review.append(review_text)\n",
    "\n",
    "for i in range(len(review)):\n",
    "    if review[i].startswith(\"'\") and review[i].endswith(\"'\"):\n",
    "        review[i] = review[i][1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente tenemos todos los datos limpios, y si no se ha notado, una vez que éstos se extraen se les agrega las comillas dobles (\") de manera automática, entonces se ha cumplido el objetivo principal de la transformación del archivo user_reviews. Sin embargo, también se nota que dentro de reviews hay varios comentarios, por ende \"funny\", que es la primera columna de reviews se repite varias veces; para asegurarnos que todo esté bien se hace una lista que contenga la cantidad de veces que aparezca \"funny\" en cada fila de reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25799"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59305"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "for i in range(len(reviews)):\n",
    "    count_funny = reviews[i].count(\"'funny':\")\n",
    "    counter.append(count_funny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comprobamos que la suma de nuestro contador y que la cantidad de datos de funny sea la misma. Como todo está en orden entonces estamos listos para formar nuestro diccionario, pero nótese que se deben formar dos diccionarios: Uno para reviews y otro para data_reviews en general, dado que reviews en sí tiene columnas que organizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(funny) - sum(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada fila de nuestro archivo final debe tener aproximadamente la siguiente estructura:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    data_reviews = {\n",
    "        \"user_id\" : user_id[i],\n",
    "        \"user_url\" : user_url[i],\n",
    "        \"reviews\" : reviews_modified[i]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero organizamos el diccionario para reviews:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la función form_review que se encarga de crear el diccionario linea por linea para cada review. Finalmente se recopilan los reviews en un diccionario final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_review(count):\n",
    "    t = sum(counter[:counter[count]])\n",
    "    reviews_line = []\n",
    "    for i in range(sum(counter[:count]), sum(counter[:count])  + counter[count]):\n",
    "        new_review = {\n",
    "            \"funny\" : funny[i],\n",
    "            \"posted\" : posted[i],\n",
    "            \"last_edited\" : last_edited[i],\n",
    "            \"item_id\" : item_id[i],\n",
    "            \"helpful\" : helpful[i],\n",
    "            \"recommend\" : recommend[i],\n",
    "            \"review\" : review[i]\n",
    "        }\n",
    "        reviews_line.append(new_review)\n",
    "    return reviews_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_modified = []\n",
    "for i in range(len(counter)):\n",
    "    reviews_modified.append(form_review(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se crea el diccionario final para nuestro archivo json ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reviews = []\n",
    "for i in range(len(user_id)):\n",
    "    data = {\n",
    "        \"user_id\" : user_id[i],\n",
    "        \"user_url\" : user_url[i],\n",
    "        \"reviews\" : reviews_modified[i]\n",
    "    }  \n",
    "    data_reviews.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos en un archivo JSON\n",
    "with open('data_reviews.json', 'w') as json_file:\n",
    "    for review_data in data_reviews:\n",
    "        json.dump(review_data, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... y finalmente cargamos esto en nuestro DataFrame user_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON en un DataFrame\n",
    "user_reviews = pd.read_json('data_reviews.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- users_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, necesitamos hacer el mismo proceso de limpieza pero para crear el archivo users_items. Se sigue un proceso muy similar que con user_reviews, por no decir que es prácticamente el mismo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    No se presentaron cambios significativos en el código, así que no se comentará este extracto por extracto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jlines = []\n",
    "# Abrir el archivo JSON en modo lectura\n",
    "with open('australian_users_items.json', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Guardar las líneas del archivo JSON\n",
    "for line in lines:\n",
    "    jlines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = []\n",
    "items_count = []\n",
    "steam_id = []\n",
    "user_url = []\n",
    "\n",
    "# Patrón de búsqueda usando comillas simples en lugar de dobles\n",
    "pattern = r\"'user_id':\\s+'([^']+)'[^}]*'items_count':\\s+(\\d+)[^}]*'steam_id':\\s+'([^']+)'[^}]*'user_url':\\s+'([^']+)'\"\n",
    "\n",
    "for i in range(len(jlines)):\n",
    "    # Contenido de la línea con comillas simples\n",
    "    line = jlines[i]\n",
    "\n",
    "    match = re.search(pattern, line)\n",
    "    if match:\n",
    "        user_id.append(match.group(1))\n",
    "        items_count.append(int(match.group(2)))\n",
    "        steam_id.append(match.group(3))\n",
    "        user_url.append(match.group(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "\n",
    "for i in range(len(jlines)):\n",
    "    # Contenido de la línea con comillas simples\n",
    "    line = jlines[i]\n",
    "\n",
    "    # Encontrar la posición del inicio de la lista de items\n",
    "    items_start = line.find(\"\\'items\\': \") + len(\"\\'items\\': \")\n",
    "\n",
    "    # Extraer la lista de items (incluyendo los corchetes)\n",
    "    items_info = line[items_start:]\n",
    "\n",
    "    # Eliminar el corchete final si está presente\n",
    "    if items_info.endswith(\"}\"):\n",
    "        items_info = items_info[:-1]\n",
    "    \n",
    "    items.append(items_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data_items = []\n",
    "\n",
    "for item in items:\n",
    "    # Encuentra los datos entre '[' y ']' en cada revisión -> Para extraer todos los caracteres de reviews\n",
    "    matches = re.findall(r'\\{(.*?)\\}', item)\n",
    "    for match in matches:\n",
    "        extracted_data_items.append('{'+match+'}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id = []\n",
    "item_name = []\n",
    "playtime_forever = []\n",
    "playtime_2weeks = []\n",
    "\n",
    "# Línea de ejemplo\n",
    "for i in range(len(extracted_data_items)):\n",
    "    line = extracted_data_items[i]\n",
    "    match_item_id = re.search(r\"'item_id':\\s+'([^']+)'[^}]\", line)\n",
    "    match_item_name = re.search(r\"'item_name':\\s+\\\"([^\\\"]+)\\\"\", line)\n",
    "    match_playtime_forever = re.search(r\"'playtime_forever':\\s+(\\d+)[^}]\", line)\n",
    "    match_playtime_2weeks = re.search(r\"'playtime_2weeks':\\s+(\\d+)\", line)\n",
    "\n",
    "    if match_item_id:\n",
    "        item_id.append(match_item_id.group(1))\n",
    "    if match_item_name:\n",
    "        item_name.append(match_item_name.group(1))\n",
    "    if not match_item_name:\n",
    "        match_item_name = re.search(r\"'item_name':\\s+'([^']+)'\", line)\n",
    "        if match_item_name:\n",
    "            item_name.append(match_item_name.group(1))\n",
    "    if match_playtime_forever:\n",
    "        playtime_forever.append(match_playtime_forever.group(1))\n",
    "    if match_playtime_2weeks:\n",
    "        playtime_2weeks.append(match_playtime_2weeks.group(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "for i in range(len(items)):\n",
    "    count_item_id = items[i].count(\"'item_id':\")\n",
    "    counter.append(count_item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_item(count):\n",
    "    t = sum(counter[:counter[count]])\n",
    "    item_line = []\n",
    "    for i in range(sum(counter[:count]), sum(counter[:count])  + counter[count]):\n",
    "        new_item = {\n",
    "            \"item_id\" : item_id[i],\n",
    "            \"item_name\" : item_name[i],\n",
    "            \"playtime_forever\" : playtime_forever[i],\n",
    "            \"playtime_2weeks\" : playtime_2weeks[i]\n",
    "        }\n",
    "        item_line.append(new_item)\n",
    "    return item_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_modified = []\n",
    "for i in range(len(counter)):\n",
    "    items_modified.append(form_item(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_items = []\n",
    "for i in range(len(user_id)):\n",
    "    data = {\n",
    "        \"user_id\" : user_id[i],\n",
    "        \"items_count\" : items_count[i],\n",
    "        \"steam_id\" : steam_id[i],\n",
    "        \"user_url\" : user_url[i],\n",
    "        \"items\" : items_modified[i]\n",
    "    }  \n",
    "    data_items.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos en un archivo JSON\n",
    "with open('data_items.json', 'w') as json_file:\n",
    "    for items_data in data_items:\n",
    "        json.dump(items_data, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo JSON en un DataFrame\n",
    "users_items = pd.read_json('data_items.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, ya se tienen los datos limpios pero al ser tantos y tener recursos tan limitados lo mejor sería encontrar una forma de optimizar dichos datos. Se ve potencial en reemplazar las reseñas de user_reviews['reviews']..['reviews'] por un análisis de sentimiento con NLP con la siguiente escala: debe tomar el valor '0' si es malo, '1' si es neutral y '2' si es positivo. Esta nueva columna debe reemplazar la de user_reviews.review para facilitar el trabajo de los modelos de machine learning y el análisis de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Librerias necesarias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer el NLP el primer obstáculo que presentamos es que algunos de las reseñas se encuentran en otros idiomas diferentes del inglés (que es el idioma en que tenemos los datos), así que a modo de exploración nos conviene saber la cantidad de frases que no se encuentran en inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = []\n",
    "index = []\n",
    "phrases = []\n",
    "pattern = re.compile(r'^[a-zA-Z]+$')\n",
    "\n",
    "for i, text in enumerate(review):\n",
    "    if bool(pattern.match(text)):\n",
    "        detected_language = detect(text)\n",
    "        if detected_language != 'en':\n",
    "            language.append(detected_language) \n",
    "            index.append(i) # Es una excelente idea saber en qué indice dento de reviews se encuentra ubicada la reseña\n",
    "            phrases.append(review[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que tenemos un número considerable de reseñas en un idioma diferente al inglés, estaría bien no perder esos datos sino más bien traducir dichas reseñas al inglés y luego reemplzar dichos comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Si bien muchas frases identificadas en language como que pertenecen a otro idioma en realidad no es así, esto no afecta en nada porque finalmente se van a traducir al inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = []\n",
    "for i in range(len(phrases)):\n",
    "    if len(phrases[i]) < 5000:    # Hay un comentario no útil que tienen más de 5000 caracteres\n",
    "        traductor = GoogleTranslator(source=language[i], target='en')\n",
    "        translated.append(traductor.translate(phrases[i]))\n",
    "    else:\n",
    "        translated.append(phrases[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar las traducciones de las reseñas\n",
    "for i in range(len(translated)):\n",
    "    review[index[i]] = translated[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que se tiene todas las reseñas en inglés se vuelve a formar el archivo json pero con la información modificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "for i in range(len(reviews)):\n",
    "    count_funny = reviews[i].count(\"'funny':\")\n",
    "    counter.append(count_funny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_modified = []\n",
    "for i in range(len(counter)):\n",
    "    reviews_modified.append(form_review(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer la información de las tres columnas principales del archivo json original\n",
    "user_id = []\n",
    "user_url = []\n",
    "reviews = []\n",
    "\n",
    "for line in jlines:\n",
    "    match = re.search(r\"'user_id':\\s+'([^']+)'[^}]*'user_url':\\s+'([^']+)'[^}]*'reviews':\\s+(\\[.*\\])\", line)\n",
    "    if match:\n",
    "        user_id.append(match.group(1))\n",
    "        user_url.append(match.group(2))\n",
    "        reviews.append(match.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reviews = []\n",
    "for i in range(len(user_id)):\n",
    "    data = {\n",
    "        \"user_id\" : user_id[i],\n",
    "        \"user_url\" : user_url[i],\n",
    "        \"reviews\" : reviews_modified[i]\n",
    "    }  \n",
    "    data_reviews.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos en un archivo JSON\n",
    "with open('data_reviews.json', 'w') as json_file:\n",
    "    for review_data in data_reviews:\n",
    "        json.dump(review_data, json_file)\n",
    "        json_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame en un archivo JSON\n",
    "user_reviews.to_json('data_reviews.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que se tienen todas las reseñas en el idioma adecuado, ahora se hace el modelaje de NLP. Se crean las variables y se entrena el modelo, como lo que se quiere es clasificar las reseñas como positivas, negativas o neutrales, un clasificador de Naive Bayes Gaussiano sería el preciso para ésta tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.DataFrame(review) # Se crea el DataFrame de reviews para que se puedan procesar todos los datos\n",
    "cv = CountVectorizer(max_features = 1500)# solo toma 1500 palabras\n",
    "X = cv.fit_transform(df_reviews[0]).toarray() \n",
    "y = df_reviews.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.02, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se procede con realizar un análisis de sentimiento en cada reseña. Primero se inicializan las herramientas sia, ps y all_stopwords; luego se crea la función analyze_review y finalmente se realiza la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el analizador de sentimientos\n",
    "sia = SentimentIntensityAnalyzer() \n",
    "\n",
    "# Inicializar el stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Obtener la lista de stopwords en inglés\n",
    "all_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def analyze_review(new_review):\n",
    "    # Preprocesamiento del texto\n",
    "    new_review = re.sub('[^a-zA-Z]', ' ', new_review.lower())\n",
    "    new_review = new_review.replace(\" t \", \"ot \")\n",
    "    new_review = ' '.join([ps.stem(word) for word in new_review.split() if word not in all_stopwords])\n",
    "\n",
    "    # Convertir el texto preprocesado en matriz\n",
    "    new_corpus = [new_review]\n",
    "    new_X_test = cv.transform(new_corpus).toarray()\n",
    "\n",
    "    # Calcular el puntaje de sentimiento\n",
    "    sentiment_score = sia.polarity_scores(new_review)['compound']\n",
    "\n",
    "    # Determinar el sentimiento basado en el puntaje\n",
    "    if sentiment_score > 0:\n",
    "        sentiment = 2  # Positivo\n",
    "    elif sentiment_score < 0:\n",
    "        sentiment = 0  # Negativo\n",
    "    else:\n",
    "        sentiment = 1  # Neutral\"\"\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = []\n",
    "for i in range(len(review)):\n",
    "    classification.append(analyze_review(review[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos la clasificación de cada reseña, se reemplaza dicha reseña por su calificación. Seguidamente se guardan los datos en el archivo json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario que mapea las revisiones a sus clasificaciones correspondientes\n",
    "mapeo_revisiones = {review[i]: classification[i] for i in range(len(review))}\n",
    "\n",
    "# Recorrer el DataFrame user_reviews_copy una sola vez\n",
    "for i in range(len(user_reviews)):\n",
    "    for j in range(len(user_reviews['reviews'][i])):\n",
    "        review_actual = user_reviews['reviews'][i][j]['review']\n",
    "        # Verificar si la revisión actual está en el diccionario de mapeo\n",
    "        if review_actual in mapeo_revisiones:\n",
    "            # Reemplazar la revisión con su clasificación correspondiente\n",
    "            user_reviews['reviews'][i][j]['review'] = mapeo_revisiones[review_actual]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos en un archivo JSON\n",
    "user_reviews.to_json('data_reviews.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones alimentadoras de la API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se desea hacer una API para facilitar algunas consultas en específico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera función es def userdata( User_id : str ): La cual devuelve la cantidad de dinero gastado por el usuario, el porcentaje de recomendación en base a reviews.recommend y cantidad de items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userdata( User_id : str ): \n",
    "    users = list(set(users_items['user_id']))\n",
    "    if User_id in users:\n",
    "        # Filtrar los juegos comprados por el usuario\n",
    "        user_games = set()  # Evita tener datos duplicados\n",
    "        for _, row in users_items[users_items['user_id'] == User_id].iterrows():\n",
    "            user_games.update(item['item_name'] for item in row['items'])\n",
    "        \n",
    "        # Calcular el dinero gastado por el usuario\n",
    "        amount_spend = 0\n",
    "        for _, game_row in steam_games[steam_games['app_name'].isin(user_games)].iterrows():\n",
    "            game_price = game_row['price']\n",
    "            if game_price not in ['Free to Play', 'Free', None, 'Third-party','Free To Play','Free Movie','Install Now']:\n",
    "                amount_spend += float(game_price)\n",
    "\n",
    "        # Calcular la cantidad de juegos que tiene el usuario\n",
    "        cant_items = len(user_games)\n",
    "\n",
    "        # Calcular el porcentaje de recomendación\n",
    "        total = 0\n",
    "        recomendados = 0\n",
    "        for _, row in user_reviews[user_reviews['user_id'] == User_id].iterrows():\n",
    "            for review in row['reviews']:\n",
    "                if review['recommend'] == 'True':\n",
    "                    recomendados += 1\n",
    "                total += 1\n",
    "        porcentaje_recom = (recomendados / total) * 100 \n",
    "\n",
    "        print(f'La cantidad de dinero gastado por el usuario es: ${round(amount_spend, 2)}\\n'\n",
    "            f'Porcentaje de recomendación de juegos: {porcentaje_recom:.2f}%\\n'\n",
    "            f'Cantidad de juegos que tiene el usuario: {cant_items}')\n",
    "    else:\n",
    "        print('El usuario que brinda no se encuentra en la base de datos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de dinero gastado por el usuario es: $6165.06\n",
      "Porcentaje de recomendación de juegos: 100.00%\n",
      "Cantidad de juegos que tiene el usuario: 885\n"
     ]
    }
   ],
   "source": [
    "userdata('js41637')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se hace la función def countreviews(first_date, last_date : str ): La cual retorna la cantidad de usuarios que realizaron reviews entre dos fechas dadas y, el porcentaje de recomendación de los mismos en base a reviews.recommend. Primero se hace un ajuste en el formato de las fechas, luego se ejecuta la función is_valid_date para identificar si las fechas están completas, y finalmente se crea la funcion countreviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero se deben modificar las fechas que se tienen en el archivo json\n",
    "def update_date(original_date):\n",
    "    try:\n",
    "        parsed_date = datetime.strptime(original_date, \"%B %d %Y\")\n",
    "        formatted_date = parsed_date.strftime(\"%Y-%m-%d\")\n",
    "        return formatted_date\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se aplica la función update_date para reemplazar las fechas en user_reviews\n",
    "for i in range(len(user_reviews)):\n",
    "    for j in range(len(user_reviews['reviews'][i])):\n",
    "        if user_reviews['reviews'][i][j]['posted'] == None:\n",
    "            pass\n",
    "        else:\n",
    "            user_reviews['reviews'][i][j]['posted'] = update_date(user_reviews['reviews'][i][j]['posted'].replace(',','').replace('.','').replace('Posted ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los datos modificados en un archivo JSON\n",
    "user_reviews.to_json('data_reviews.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_date(date_string):\n",
    "    try:\n",
    "        datetime.strptime(date_string, '%Y-%m-%d')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    También se debe saber cuál es la primera y última fecha en reviews para que la función retorne valores dentro de ese mismo rango de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera fecha:2010-10-16 00:00:00\n",
      "última fecha:2015-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "dates = [review['posted'] for reviews_list in user_reviews['reviews'] for review in reviews_list]\n",
    "fechas_validas = [fecha for fecha in dates if fecha is not None]\n",
    "fechas_datetime = [datetime.strptime(fecha, '%Y-%m-%d') for fecha in fechas_validas]\n",
    "print(f'Primera fecha:{min(fechas_datetime)}')\n",
    "print(f'última fecha:{max(fechas_datetime)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countreviews(first_date, last_date : str ): \n",
    "    if datetime.strptime(first_date, '%Y-%m-%d') > datetime.strptime('2010-10-16', '%Y-%m-%d') and datetime.strptime(last_date, '%Y-%m-%d') < datetime.strptime('2015-12-31', '%Y-%m-%d') :\n",
    "        usuarios = set()\n",
    "        total = 0\n",
    "        recomendados = 0\n",
    "        \n",
    "        for i in range(len(user_reviews)):\n",
    "            for review in user_reviews['reviews'][i]:\n",
    "                posted_date = review['posted']\n",
    "                if posted_date and is_valid_date(posted_date):\n",
    "                    if first_date <= posted_date <= last_date:\n",
    "                        usuarios.add(user_reviews['user_id'][i])\n",
    "                        if review['recommend'] == \"True\":\n",
    "                            total += 1\n",
    "                            recomendados += 1\n",
    "                        else:\n",
    "                            total += 1\n",
    "        \n",
    "        usuarios_count = len(usuarios)\n",
    "        porcentaje_recom = (recomendados / total) * 100\n",
    "        \n",
    "        print(f'Cantidad de usuarios que realizaron reviews entre las fechas {first_date} y {last_date} es de: {usuarios_count}\\n'\n",
    "            f'Porcentaje de juegos recomendados entre las fechas {first_date} y {last_date} es de: {round(porcentaje_recom, 2)}%')\n",
    "    else:\n",
    "        print('El rango de fechas dado está por fuera del de la base de datos. Se encuentra información desde 2010-10-16 hasta 2015-12-31')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios que realizaron reviews entre las fechas 2012-01-01 y 2015-01-01 es de: 16548\n",
      "Porcentaje de juegos recomendados entre las fechas 2012-01-01 y 2015-01-01 es de: 92.31%\n"
     ]
    }
   ],
   "source": [
    "countreviews('2012-01-01','2015-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se crea la función def genre( género : str ): Que devuelve el puesto en el que se encuentra un género sobre el ranking de los mismos analizado bajo la columna PlayTimeForever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se crean las funciones playtime(para extraer el total de playtime_forever por cada juego), game_genres(retorna los género de un juego dado), genres_list(retorna una lista con el total de géneros); para finalmente hacer la función genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playtime(game):\n",
    "    filtered_items = [item['playtime_forever'] for items in users_items['items'] for item in items if item['item_name'] == game]\n",
    "    total_playtime = sum(map(int, filtered_items))\n",
    "    return total_playtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_genres(game):\n",
    "    matching_games = steam_games[steam_games['app_name'] == game]\n",
    "    genres = [genre for genres_list in matching_games['genres'].dropna() for genre in genres_list]\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genres_list():\n",
    "    # Descomponer las listas de géneros en filas separadas\n",
    "    exploded_genres = steam_games['genres'].explode()\n",
    "    # Obtener los géneros únicos y eliminar los valores nulos\n",
    "    unique_genres = exploded_genres.dropna().unique()\n",
    "    return unique_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre( género : str ):\n",
    "    g_list = genres_list()\n",
    "    if género in g_list:\n",
    "        games = set(steam_games['app_name'])  # Utilizar un conjunto en lugar de una lista para buscar de manera más eficiente\n",
    "        total_playtime = {}\n",
    "\n",
    "        for i in range(len(users_items['items'])):\n",
    "            for item in users_items['items'][i]:\n",
    "                if 'playtime_forever' in item:\n",
    "                    game_name = item['item_name']\n",
    "                    playtime_forever = int(item['playtime_forever'])\n",
    "                    \n",
    "                    if game_name in games:\n",
    "                        if game_name not in total_playtime:\n",
    "                            total_playtime[game_name] = playtime_forever\n",
    "                        else:\n",
    "                            total_playtime[game_name] += playtime_forever\n",
    "\n",
    "        games_by_genre = {}\n",
    "\n",
    "        for i in range(len(steam_games)):\n",
    "            app_name = steam_games['app_name'][i]\n",
    "            genres = steam_games['genres'][i]\n",
    "            \n",
    "            if genres is not None:\n",
    "                for genre in genres:\n",
    "                    if genre not in games_by_genre:\n",
    "                        games_by_genre[genre] = []\n",
    "                    games_by_genre[genre].append(app_name)\n",
    "\n",
    "        total_playtime_by_genre = {}  # Diccionario para almacenar el tiempo total de juego por género\n",
    "\n",
    "        for i in range(len(g_list)):\n",
    "            genre = g_list[i]\n",
    "            if genre in games_by_genre:\n",
    "                total_time = 0  # Inicializar el tiempo total en cero para este género\n",
    "                for game in games_by_genre[genre]:\n",
    "                    if game in total_playtime:\n",
    "                        total_time += total_playtime[game]\n",
    "                total_playtime_by_genre[genre] = total_time\n",
    "\n",
    "        sorted_genres_by_playtime = sorted(total_playtime_by_genre.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i in range(len(sorted_genres_by_playtime)):\n",
    "            if sorted_genres_by_playtime[i][0] == género:\n",
    "                print(f'El género {género} se encuentra en el puesto número {i+1} sobre el ranking de los géneros con mayor cantidad de tiempo jugado')\n",
    "    \n",
    "    else:\n",
    "        print('El género brindado no se encuentra en la base de datos, por favor revíselo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El género Simulation se encuentra en el puesto número 4 sobre el ranking de los géneros con mayor cantidad de tiempo jugado\n"
     ]
    }
   ],
   "source": [
    "genre('Simulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se hace la función def userforgenre( género : str ): Que retorna el top 5 de usuarios con más horas de juego en el género dado, con su URL (del user) y user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userforgenre(género: str):\n",
    "    g_list = genres_list()\n",
    "    if género in g_list:\n",
    "        user_games_playtime = {}\n",
    "        games_by_genre = {}\n",
    "\n",
    "        for i in range(len(users_items['user_id'])):\n",
    "            user_id = users_items['user_id'][i]\n",
    "            for item in users_items['items'][i]:\n",
    "                if 'playtime_forever' in item:\n",
    "                    game_name = item['item_name']\n",
    "                    playtime_forever = int(item['playtime_forever'])\n",
    "                    \n",
    "                    if user_id not in user_games_playtime:\n",
    "                        user_games_playtime[user_id] = []\n",
    "                    user_games_playtime[user_id].append((game_name, playtime_forever))\n",
    "\n",
    "        for i in range(len(steam_games)):\n",
    "            app_name = steam_games['app_name'][i]\n",
    "            genres = steam_games['genres'][i]\n",
    "                \n",
    "            if genres is not None:\n",
    "                for genre in genres:\n",
    "                    if genre not in games_by_genre:\n",
    "                        games_by_genre[genre] = []\n",
    "                    games_by_genre[genre].append(app_name)\n",
    "\n",
    "        target_genre_games = set(games_by_genre.get(género, []))\n",
    "\n",
    "        genre_user_playtime = []\n",
    "        for user_id, games_playtime in user_games_playtime.items():\n",
    "            user_genre_playtime = 0\n",
    "            for game_name, playtime_forever in games_playtime:\n",
    "                if game_name in target_genre_games:\n",
    "                    user_genre_playtime += playtime_forever\n",
    "            genre_user_playtime.append((user_id, user_genre_playtime))\n",
    "        \n",
    "        # Ordenar la lista en función del tiempo de juego y obtener los 5 usuarios con más playtime\n",
    "        best_gamers = sorted(genre_user_playtime, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "        user_ids = [user_id for user_id, _ in best_gamers]\n",
    "        user_urls = [users_items['user_url'][users_items['user_id'] == user_id].iloc[0] for user_id in user_ids]\n",
    "\n",
    "        result_dict = {'user_id': user_ids, 'user_url': user_urls}\n",
    "        result_df = pd.DataFrame(result_dict)\n",
    "        result_df.index += 1 # Para que el índice inicie en 1\n",
    "\n",
    "        return result_df\n",
    "    else:\n",
    "        print('El género brindado no se encuentra en la base de datos, por favor revíselo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jimmynoe</td>\n",
       "      <td>http://steamcommunity.com/id/jimmynoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clawbot44</td>\n",
       "      <td>http://steamcommunity.com/id/clawbot44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REBAS_AS_F-T</td>\n",
       "      <td>http://steamcommunity.com/id/REBAS_AS_F-T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evilutional</td>\n",
       "      <td>http://steamcommunity.com/id/Evilutional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tsunamitad</td>\n",
       "      <td>http://steamcommunity.com/id/tsunamitad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                   user_url\n",
       "1      jimmynoe      http://steamcommunity.com/id/jimmynoe\n",
       "2     clawbot44     http://steamcommunity.com/id/clawbot44\n",
       "3  REBAS_AS_F-T  http://steamcommunity.com/id/REBAS_AS_F-T\n",
       "4   Evilutional   http://steamcommunity.com/id/Evilutional\n",
       "5    tsunamitad    http://steamcommunity.com/id/tsunamitad"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userforgenre('Simulation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra de las funciones es def developer( desarrollador : str ): Que debe retornar la cantidad de items y porcentaje de contenido Free por año según empresa desarrolladora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Free to Try', 'Play Now', 'Play for Free!', 'Play WARMACHINE: Tactics Demo', 'Free to Play', 'Play the Demo', 'Install Theme', None, 'Third-party', 'Free', 'Free HITMAN™ Holiday Pack', 'Starting at $449.00', 'Install Now', 'Free Demo', 'Starting at $499.00', 'Free Mod', 'Free Movie', 'Free to Use', 'Free To Play']\n"
     ]
    }
   ],
   "source": [
    "# Primero se debe saber que tipo de contenido free hay\n",
    "prices = list(set(steam_games['price']))\n",
    "posibles = []\n",
    "for i in range(len(prices)):\n",
    "    if type(prices[i]) != float:\n",
    "        posibles.append(prices[i])\n",
    "posibles = list(set(posibles))\n",
    "print(posibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def developer(desarrollador: str):\n",
    "    \"\"\"Cantidad de items y porcentaje de contenido Free por año según empresa desarrolladora. Ejemplo de salida:\"\"\"\n",
    "    developers = list(set(steam_games['developer']))\n",
    "    if desarrollador in developers:\n",
    "        años = []\n",
    "        cantidad = 0\n",
    "        free = 0\n",
    "        \n",
    "        for i in range(len(steam_games)):\n",
    "            if steam_games['developer'][i] == desarrollador:\n",
    "                cantidad += 1\n",
    "                if steam_games['price'][i] in ['Free Demo', 'Free Mod', 'Free to Use', 'Free To Play', 'Free Movie', 'Play for Free!', 'Free to Try', 'Free', 'Free to Play', 'Free HITMAN™ Holiday Pack']:\n",
    "                    free += 1\n",
    "                if steam_games['release_date'][i] is not None and is_valid_date(steam_games['release_date'][i]):\n",
    "                    año = steam_games['release_date'][i][:4]\n",
    "                    años.append(año)\n",
    "        años = list(set(años))  # Eliminar duplicados\n",
    "        porcentaje_free_por_año = (free/cantidad)*100\n",
    "\n",
    "        print(f'Cantidad total de juegos: {cantidad}')\n",
    "        if cantidad != 0:\n",
    "            print(f'Porcentaje de contenido free: {porcentaje_free_por_año:.2f}%')\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[''] = años\n",
    "        df[desarrollador] = (str(round(porcentaje_free_por_año,2)))+'%'\n",
    "        return df\n",
    "    else: \n",
    "        print('El desarrollador brindado no se encuentra en la base de datos, por favor revíselo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de juegos: 1\n",
      "Porcentaje de contenido free: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ExtinctionArts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ExtinctionArts\n",
       "0  2017           0.0%"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developer('ExtinctionArts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se hace la funcion def sentiment_analysis( año : int ): Que según el año de lanzamiento, se devuelve una lista con la cantidad de registros de reseñas de usuarios que se encuentren categorizados con un análisis de sentimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis( año : int ): \n",
    "    if año > 2009 and año < 2016:\n",
    "        positivo = 0\n",
    "        negativo = 0\n",
    "        neutral = 0\n",
    "        for i in range(len(user_reviews)):\n",
    "            for j in range(len(user_reviews['reviews'][i])):\n",
    "                if user_reviews['reviews'][i][j]['posted'] is None:\n",
    "                    pass\n",
    "                if user_reviews['reviews'][i][j]['posted'] is not None:\n",
    "                    if int(user_reviews['reviews'][i][j]['posted'][:4]) == año:\n",
    "                        if user_reviews['reviews'][i][j]['review'] == 2:\n",
    "                            positivo += 1\n",
    "                        elif user_reviews['reviews'][i][j]['review'] == 1:\n",
    "                            neutral += 1\n",
    "                        else:\n",
    "                            negativo += 1\n",
    "\n",
    "        resultado = {'Positivo':positivo, 'Neutral':neutral,'Negativo':negativo}\n",
    "        return resultado\n",
    "    else:\n",
    "        print('El añodado está por fuera del de la base de datos. Se encuentra información desde 2010-10-16 hasta 2015-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positivo': 4310, 'Neutral': 1698, 'Negativo': 784}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de la API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primero se crea el entorno virtual con el comando python -m venv proyecto-env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se activa el entorno virtual: proyecto-env\\Scripts\\activate.bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se instala fastapi: pip install fastapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instalar uvicorn: pip install \"uvicorn[standard]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hacer el freeze de los requirements: pip freeze > requirements.txt --> Si luego se necesita instalar otra librería más, se vuelve a ejecutar este comando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se crea el archivo main.py y se importa FastAPI: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from fastapi import FastAPI\n",
    "\n",
    "    app = FastAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se forman todas las funciones necesarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Levantar el servidor: python -m uvicorn main:app --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos todas las funciones para nuestra Api, es útil modificar los archivos y eliminar todas las columnas que no se utilizan para garantizar que el espacio y el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del steam_games['publisher']\n",
    "del steam_games['title']\n",
    "del steam_games['url']\n",
    "del steam_games['tags']\n",
    "del steam_games['specs']\n",
    "del steam_games['early_access']\n",
    "del steam_games['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica las filas donde todas las columnas son None\n",
    "rows_to_remove = steam_games[steam_games.isnull().all(axis=1)].index\n",
    "\n",
    "# Luego, utiliza el método 'drop' para eliminar estas filas del DataFrame\n",
    "steam_games = steam_games.drop(rows_to_remove)\n",
    "\n",
    "# Resetear los index\n",
    "steam_games.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games.to_json('output_steam_games.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_reviews)):\n",
    "    for j in range(len(user_reviews['reviews'][i])):\n",
    "        del user_reviews['reviews'][i][j]['funny']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_reviews)):\n",
    "    for j in range(len(user_reviews['reviews'][i])):\n",
    "        del user_reviews['reviews'][i][j]['last_edited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_reviews)):\n",
    "    for j in range(len(user_reviews['reviews'][i])):\n",
    "        del user_reviews['reviews'][i][j]['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_reviews)):\n",
    "    for j in range(len(user_reviews['reviews'][i])):\n",
    "        del user_reviews['reviews'][i][j]['helpful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews.to_json('data_reviews.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del users_items['items_count']\n",
    "del users_items['steam_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(users_items)):\n",
    "    for j in range(len(users_items['items'][i])):\n",
    "        del users_items['items'][i][j]['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(users_items)):\n",
    "    for j in range(len(users_items['items'][i])):\n",
    "        del users_items['items'][i][j]['playtime_2weeks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items.to_json('data_items.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    El archivo de data_items sigue pesando mucho, es por eso que se va a comprimir y luego leer el dataframe de nuevo para asegurar que todo está bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para comprimir el archivo\n",
    "with open('data_items.json', 'rb') as archivo_json:\n",
    "    with gzip.open('data_items.json' + '.gz', 'wb') as archivo_json_comprimido:\n",
    "        archivo_json_comprimido.writelines(archivo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para leer el archivo json.gzip\n",
    "with gzip.open('data_items.json.gz', 'rb') as archivo_json_comprimido:\n",
    "    users_items = pd.read_json(archivo_json_comprimido, lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "with gzip.open('data_items.json.gz', 'rb') as archivo_json_comprimido:\n",
    "    for linea in archivo_json_comprimido:\n",
    "        datos_json = linea.decode('utf-8')\n",
    "        objeto_json = json.loads(datos_json)\n",
    "        # Añade el objeto JSON completo a la lista\n",
    "        users.append(objeto_json)\n",
    "# Crea un DataFrame a partir de la lista de objetos JSON\n",
    "users_items = pd.DataFrame(users)\n",
    "steam_games = pd.read_json('output_steam_games.json', lines=True)\n",
    "user_reviews = pd.read_json('data_reviews.json', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
